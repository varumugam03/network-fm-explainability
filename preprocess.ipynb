{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c0b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/cic-ids2018/raw/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv...\n",
      "Loading data/cic-ids2018/raw/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv...\n",
      "Loading data/cic-ids2018/raw/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv...\n",
      "Loading data/cic-ids2018/raw/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv...\n",
      "Loading data/cic-ids2018/raw/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv...\n",
      "Loading data/cic-ids2018/raw/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv...\n",
      "Loading data/cic-ids2018/raw/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv...\n",
      "Loading data/cic-ids2018/raw/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv...\n",
      "Loading data/cic-ids2018/raw/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Src IP</th>\n",
       "      <th>Src Port</th>\n",
       "      <th>Dst IP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:38</td>\n",
       "      <td>141385</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>553</td>\n",
       "      <td>3773.0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49684</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:38</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:40</td>\n",
       "      <td>279824</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1086</td>\n",
       "      <td>10527.0</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:40</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>02/03/2018 08:47:41</td>\n",
       "      <td>274016</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>1285</td>\n",
       "      <td>6141.0</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15184422</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>28/02/2018 11:59:12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Infilteration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15184423</th>\n",
       "      <td>425</td>\n",
       "      <td>6</td>\n",
       "      <td>28/02/2018 10:50:04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Infilteration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15184424</th>\n",
       "      <td>445</td>\n",
       "      <td>6</td>\n",
       "      <td>28/02/2018 12:52:55</td>\n",
       "      <td>732728</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15184425</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>28/02/2018 11:10:50</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Infilteration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15184426</th>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>28/02/2018 11:12:18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Infilteration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15184427 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dst Port Protocol            Timestamp Flow Duration Tot Fwd Pkts  \\\n",
       "0             443        6  02/03/2018 08:47:38        141385            9   \n",
       "1           49684        6  02/03/2018 08:47:38           281            2   \n",
       "2             443        6  02/03/2018 08:47:40        279824           11   \n",
       "3             443        6  02/03/2018 08:47:40           132            2   \n",
       "4             443        6  02/03/2018 08:47:41        274016            9   \n",
       "...           ...      ...                  ...           ...          ...   \n",
       "15184422       23        6  28/02/2018 11:59:12             3            1   \n",
       "15184423      425        6  28/02/2018 10:50:04             2            1   \n",
       "15184424      445        6  28/02/2018 12:52:55        732728            2   \n",
       "15184425       23        6  28/02/2018 11:10:50            22            1   \n",
       "15184426      443        6  28/02/2018 11:12:18             2            1   \n",
       "\n",
       "         Tot Bwd Pkts TotLen Fwd Pkts TotLen Bwd Pkts Fwd Pkt Len Max  \\\n",
       "0                   7             553          3773.0             202   \n",
       "1                   1              38             0.0              38   \n",
       "2                  15            1086         10527.0             385   \n",
       "3                   0               0             0.0               0   \n",
       "4                  13            1285          6141.0             517   \n",
       "...               ...             ...             ...             ...   \n",
       "15184422            1               0               0               0   \n",
       "15184423            1               0               0               0   \n",
       "15184424            2               0               0               0   \n",
       "15184425            1               0               0               0   \n",
       "15184426            1               0               0               0   \n",
       "\n",
       "         Fwd Pkt Len Min  ... Active Min Idle Mean Idle Std Idle Max Idle Min  \\\n",
       "0                      0  ...        0.0       0.0      0.0      0.0      0.0   \n",
       "1                      0  ...        0.0       0.0      0.0      0.0      0.0   \n",
       "2                      0  ...        0.0       0.0      0.0      0.0      0.0   \n",
       "3                      0  ...        0.0       0.0      0.0      0.0      0.0   \n",
       "4                      0  ...        0.0       0.0      0.0      0.0      0.0   \n",
       "...                  ...  ...        ...       ...      ...      ...      ...   \n",
       "15184422               0  ...          0         0        0        0        0   \n",
       "15184423               0  ...          0         0        0        0        0   \n",
       "15184424               0  ...          0         0        0        0        0   \n",
       "15184425               0  ...          0         0        0        0        0   \n",
       "15184426               0  ...          0         0        0        0        0   \n",
       "\n",
       "                  Label Flow ID Src IP Src Port Dst IP  \n",
       "0                Benign     NaN    NaN      NaN    NaN  \n",
       "1                Benign     NaN    NaN      NaN    NaN  \n",
       "2                Benign     NaN    NaN      NaN    NaN  \n",
       "3                Benign     NaN    NaN      NaN    NaN  \n",
       "4                Benign     NaN    NaN      NaN    NaN  \n",
       "...                 ...     ...    ...      ...    ...  \n",
       "15184422  Infilteration     NaN    NaN      NaN    NaN  \n",
       "15184423  Infilteration     NaN    NaN      NaN    NaN  \n",
       "15184424         Benign     NaN    NaN      NaN    NaN  \n",
       "15184425  Infilteration     NaN    NaN      NaN    NaN  \n",
       "15184426  Infilteration     NaN    NaN      NaN    NaN  \n",
       "\n",
       "[15184427 rows x 84 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"data/cic-ids2018/\")\n",
    "\n",
    "# Move all CSV files into a raw subdirectory\n",
    "raw_dir = data_dir / \"raw\"\n",
    "raw_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for file in data_dir.glob(\"*.csv\"):\n",
    "    print(f\"Moving {file} to {raw_dir}...\")\n",
    "    file.rename(raw_dir / file.name)\n",
    "\n",
    "# Load all CSV files from the raw directory\n",
    "all_files = sorted(raw_dir.glob(\"*.csv\"))\n",
    "all_dfs = []\n",
    "for filename in all_files:\n",
    "    print(f\"Loading {filename}...\")\n",
    "    all_dfs.append(pd.read_csv(filename, low_memory=False))\n",
    "\n",
    "df: pd.DataFrame = pd.concat(all_dfs, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaffb4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_cols = [\"Flow ID\", \"Src IP\", \"Src Port\", \"Dst IP\", \"Timestamp\"]\n",
    "df = df.drop(columns=identifier_cols)\n",
    "\n",
    "# Remove zero-variance columns\n",
    "nunique = df.nunique()\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "if len(cols_to_drop) > 0:\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    print(f\"Dropped zero-variance columns: {list(cols_to_drop)}\")\n",
    "\n",
    "# Convert feature columns to numerics\n",
    "feature_cols = [c for c in df.columns if c not in [\"Label\"]]\n",
    "df[feature_cols] = df[feature_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Remove rows with inf/-inf/NaN values\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna()\n",
    "\n",
    "# Fix label typos and remove rows with missing labels\n",
    "df[\"Fine Label\"] = df[\"Label\"].replace({\"Infilteration\": \"Infiltration\", \"SQL Injection\": np.nan, \"Label\": np.nan})\n",
    "df = df.dropna(subset=[\"Fine Label\"])\n",
    "\n",
    "# Aggregate labels into broader attack categories\n",
    "label_mapping = {\n",
    "    'Benign': 'Benign',\n",
    "    'DoS attacks-Hulk': 'DoS',\n",
    "    'DoS attacks-SlowHTTPTest': 'DoS',\n",
    "    'DoS attacks-GoldenEye': 'DoS',\n",
    "    'DoS attacks-Slowloris': 'DoS',\n",
    "    'DDOS attack-HOIC': 'DDoS',\n",
    "    'DDoS attacks-LOIC-HTTP': 'DDoS',\n",
    "    'DDOS attack-LOIC-UDP': 'DDoS',\n",
    "    'Bot': 'Bot',\n",
    "    'Brute Force -Web': 'Brute Force',\n",
    "    'Brute Force -XSS': 'Brute Force',\n",
    "    'Infiltration': 'Infiltration',\n",
    "}\n",
    "\n",
    "df['Label'] = df['Fine Label'].map(label_mapping)\n",
    "df.dropna(subset=['Label'], inplace=True)\n",
    "\n",
    "processed_dir = data_dir / \"processed\"\n",
    "processed_dir.mkdir(exist_ok=True)\n",
    "df.to_csv(processed_dir / \"cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deaf68af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dst Port', 'Protocol', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts',\n",
       "       'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max',\n",
       "       'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std',\n",
       "       'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean',\n",
       "       'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean',\n",
       "       'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot',\n",
       "       'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min',\n",
       "       'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
       "       'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags',\n",
       "       'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s',\n",
       "       'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean',\n",
       "       'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt',\n",
       "       'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt',\n",
       "       'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg',\n",
       "       'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg',\n",
       "       'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',\n",
       "       'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts',\n",
       "       'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts',\n",
       "       'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts',\n",
       "       'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max',\n",
       "       'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label',\n",
       "       'Fine Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35bd91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifier_cols = [\"Src IP\", \"Src Port\", \"Dst IP\", \"Timestamp\"]\n",
    "# df = df.drop(columns=identifier_cols)\n",
    "df.to_csv(processed_dir / \"cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff84cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove identifier columns\n",
    "df = df.drop(columns=identifier_cols)\n",
    "\n",
    "# Remove zero-variance columns\n",
    "nunique = df.nunique()\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "if len(cols_to_drop) > 0:\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    print(f\"Dropped zero-variance columns: {list(cols_to_drop)}\")\n",
    "\n",
    "# Convert feature columns to numerics\n",
    "feature_cols = [c for c in df.columns if c != \"Label\"]\n",
    "df[feature_cols] = df[feature_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Remove rows with inf/-inf/NaN values\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna()\n",
    "\n",
    "# One-hot enccode categorical features\n",
    "cat_columns = [\"Protocol\"]\n",
    "df = pd.get_dummies(df, columns=cat_columns, dtype=int)\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "feature_cols = [c for c in df.columns if c != \"Label\"]\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "df[feature_cols] = df[feature_cols].astype(np.float32)\n",
    "df\n",
    "\n",
    "# Map labels to higher-level attacks\n",
    "label_mapping = {\n",
    "    'Benign': 'Benign',\n",
    "    'DoS attacks-Hulk': 'DoS',\n",
    "    'DoS attacks-SlowHTTPTest': 'DoS',\n",
    "    'DoS attacks-GoldenEye': 'DoS',\n",
    "    'DoS attacks-Slowloris': 'DoS',\n",
    "    'DDOS attack-HOIC': 'DDoS',\n",
    "    'DDoS attacks-LOIC-HTTP': 'DDoS',\n",
    "    'DDOS attack-LOIC-UDP': 'DDoS',\n",
    "    'Bot': 'Bot',\n",
    "    'Brute Force -Web': 'Brute Force',\n",
    "    'Brute Force -XSS': 'Brute Force',\n",
    "    'Infiltration': 'Infiltration',\n",
    "}\n",
    "\n",
    "df['Label'] = df['Label'].map(label_mapping)\n",
    "df.dropna(subset=['Label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['Label']\n",
    ")\n",
    "\n",
    "# Drop 80% of the \"Benign\" samples from the training set to address class imbalance\n",
    "benign_mask = train_df['Label'] == 'Benign'\n",
    "benign_indices = train_df[benign_mask].index\n",
    "n_benign_to_drop = int(0.8 * len(benign_indices))\n",
    "indices_to_drop = np.random.choice(benign_indices, size=n_benign_to_drop, replace=False)\n",
    "train_df = train_df.drop(index=indices_to_drop)\n",
    "\n",
    "# Save preprocessed datasets\n",
    "preprocessed_dir = data_dir / \"preprocessed\"\n",
    "preprocessed_dir.mkdir(exist_ok=True)\n",
    "train_df.to_csv(preprocessed_dir / \"train.csv\", index=False)\n",
    "test_df.to_csv(preprocessed_dir / \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f6606e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a cybersecurity analyst. Your task is to explain why the following network flow is labeled as a DDoS attacks-LOIC-HTTP attack. This flow is part of the CIC-IDS2018 dataset, which includes realistic attack scenarios and benign behavior.\\n\\n    ### Ground Truth\\n    - Label (High-level): DDoS\\n    - Label (Specific Variant): DDoS attacks-LOIC-HTTP\\n\\n    ### Background on Attack\\n    LOIC-HTTP overwhelms web services with multi-threaded GET/POST requests in distributed fashion.\\n\\n    ### INSTRUCTIONS\\n    Only use the flow features and values below to construct your explanation. Do NOT reference IPs, timestamps, or any external knowledge. Justify the label using only flow-level behavioral characteristics.\\n\\n    ### Flow Features\\n    - Dst Port: 80\\n    - Flow Duration: 3904.0\\n    - Tot Fwd Pkts: 3.0\\n    - TotLen Fwd Pkts: 20.0\\n    - Fwd Pkt Len Max: 20.0\\n    - Fwd Pkt Len Mean: 6.666666667\\n    - Fwd IAT Tot: 3310.0\\n    - Fwd IAT Mean: 1655.0\\n    - Fwd IAT Max: 2937.0\\n    - Fwd IAT Min: 373.0\\n    - Flow IAT Min: 27.0\\n    - Flow IAT Max: 2937.0\\n    - Flow IAT Mean: 650.6666667\\n    - Fwd Seg Size Min: 20.0\\n    - Fwd Seg Size Avg: 6.666666667\\n    - Flow Pkts/s: 1793.032787\\n    - Fwd Pkts/s: 768.442623\\n    - Bwd Pkts/s: 1024.590164\\n    - Fwd Header Len: 72.0\\n    - Init Fwd Win Byts: 8192.0\\n    - Init Bwd Win Byts: 211.0\\n    - Pkt Len Max: 964.0\\n    - Subflow Fwd Byts: 20.0\\n    - Subflow Fwd Pkts: 3.0\\n\\n    ### Your Task\\n    Based on these features alone, write a brief explanation of why this flow is consistent with the DDoS attacks-LOIC-HTTP label.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "def generate_prompt_from_row(row):\n",
    "    attack_descriptions = {\n",
    "        'DoS attacks-Slowloris': \"Slowloris exhausts a server's resources by holding many connections open with partial HTTP requests using minimal bandwidth.\",\n",
    "        'DoS attacks-Hulk': \"Hulk generates large volumes of HTTP requests with random parameters to overwhelm the server.\",\n",
    "        'DoS attacks-GoldenEye': \"GoldenEye sends malformed HTTP requests at high frequency to degrade server responsiveness.\",\n",
    "        'DoS attacks-SlowHTTPTest': \"SlowHTTPTest sends legitimate-looking HTTP traffic very slowly to keep server connections open indefinitely.\",\n",
    "        'DDOS attack-HOIC': \"HOIC floods web servers with HTTP requests from multiple machines using booster scripts to randomize targets.\",\n",
    "        'DDoS attacks-LOIC-HTTP': \"LOIC-HTTP overwhelms web services with multi-threaded GET/POST requests in distributed fashion.\",\n",
    "        'DDOS attack-LOIC-UDP': \"LOIC-UDP floods targets with high-rate UDP packets from multiple machines.\",\n",
    "        'Bot': \"This flow is from a machine infected with Zeus or Ares botnet, which periodically exfiltrate data or perform keylogging and remote commands.\",\n",
    "        'Brute Force -Web': \"The attacker tried different username/password combinations on a web login interface in an automated fashion.\",\n",
    "        'Brute Force -XSS': \"This attack injected malicious JavaScript to exploit cross-site scripting vulnerabilities.\",\n",
    "        'Infiltration': \"A compromised internal host scanned internal network resources after being exploited through a malicious document.\",\n",
    "        'Benign': \"This flow represents normal activity in a typical corporate network, such as file transfers, browsing, or background services.\"\n",
    "    }\n",
    "\n",
    "    label = row[\"Label\"]\n",
    "    fine_label = row[\"Fine Label\"]\n",
    "    desc = attack_descriptions.get(fine_label, \"No description available.\")\n",
    "\n",
    "    prompt = dedent(f\"\"\"You are a cybersecurity analyst. Your task is to explain why the following network flow is labeled as a {fine_label} attack. This flow is part of the CIC-IDS2018 dataset, which includes realistic attack scenarios and benign behavior.\n",
    "\n",
    "    ### Ground Truth\n",
    "    - Label (High-level): {label}\n",
    "    - Label (Specific Variant): {fine_label}\n",
    "\n",
    "    ### Background on Attack\n",
    "    {desc}\n",
    "\n",
    "    ### INSTRUCTIONS\n",
    "    Only use the flow features and values below to construct your explanation. Do NOT reference IPs, timestamps, or any external knowledge. Justify the label using only flow-level behavioral characteristics.\n",
    "\n",
    "    ### Flow Features\n",
    "    - Dst Port: {row['Dst Port']}\n",
    "    - Flow Duration: {row['Flow Duration']}\n",
    "    - Tot Fwd Pkts: {row['Tot Fwd Pkts']}\n",
    "    - TotLen Fwd Pkts: {row['TotLen Fwd Pkts']}\n",
    "    - Fwd Pkt Len Max: {row['Fwd Pkt Len Max']}\n",
    "    - Fwd Pkt Len Mean: {row['Fwd Pkt Len Mean']}\n",
    "    - Fwd IAT Tot: {row['Fwd IAT Tot']}\n",
    "    - Fwd IAT Mean: {row['Fwd IAT Mean']}\n",
    "    - Fwd IAT Max: {row['Fwd IAT Max']}\n",
    "    - Fwd IAT Min: {row['Fwd IAT Min']}\n",
    "    - Flow IAT Min: {row['Flow IAT Min']}\n",
    "    - Flow IAT Max: {row['Flow IAT Max']}\n",
    "    - Flow IAT Mean: {row['Flow IAT Mean']}\n",
    "    - Fwd Seg Size Min: {row['Fwd Seg Size Min']}\n",
    "    - Fwd Seg Size Avg: {row['Fwd Seg Size Avg']}\n",
    "    - Flow Pkts/s: {row['Flow Pkts/s']}\n",
    "    - Fwd Pkts/s: {row['Fwd Pkts/s']}\n",
    "    - Bwd Pkts/s: {row['Bwd Pkts/s']}\n",
    "    - Fwd Header Len: {row['Fwd Header Len']}\n",
    "    - Init Fwd Win Byts: {row['Init Fwd Win Byts']}\n",
    "    - Init Bwd Win Byts: {row['Init Bwd Win Byts']}\n",
    "    - Pkt Len Max: {row['Pkt Len Max']}\n",
    "    - Subflow Fwd Byts: {row['Subflow Fwd Byts']}\n",
    "    - Subflow Fwd Pkts: {row['Subflow Fwd Pkts']}\n",
    "\n",
    "    ### Your Task\n",
    "    Based on these features alone, write a brief explanation of why this flow is consistent with the {fine_label} label. Make sure your response includes which features specifically lead you to believe that it is the said attack or not.\n",
    "    \"\"\")\n",
    "\n",
    "    return prompt\n",
    "\n",
    "generate_prompt_from_row(df[df[\"Label\"] == \"DDoS\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fefe403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dst Port                             80\n",
       "Protocol                            6.0\n",
       "Flow Duration                    3904.0\n",
       "Tot Fwd Pkts                        3.0\n",
       "Tot Bwd Pkts                        4.0\n",
       "                          ...          \n",
       "Idle Std                            0.0\n",
       "Idle Max                            0.0\n",
       "Idle Min                            0.0\n",
       "Label                              DDoS\n",
       "Fine Label       DDoS attacks-LOIC-HTTP\n",
       "Name: 3145788, Length: 80, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Label\"] == \"DDoS\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f773ff99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IDSDataSet\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# train_dataset = IDSDataSet(\"data/cic-ids2018/processed/train.csv\")\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_df\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from textwrap import dedent\n",
    "\n",
    "\n",
    "MODEL_ID = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "INPUT_DATA_PATH = \"data/cic-ids2018/processed/cleaned.csv\"\n",
    "OUTPUT_DATA_PATH = \"data/cic-ids2018/processed/attack_explanations.csv\"\n",
    "MAX_TIME_HOURS = 2.0  \n",
    "BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "print(\"Loading cleaned data...\")\n",
    "df = pd.read_csv(INPUT_DATA_PATH, low_memory=False)\n",
    "\n",
    "# Filter: Only Attacks (Label != Benign) TODO: I think we should also have a decent bit of benign examples in there?\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "attack_df = df[df['Label'] != 'Benign'].copy()\n",
    "print(f\"Attack samples only: {attack_df.shape}\")\n",
    "\n",
    "\n",
    "print(f\"Loading model: {MODEL_ID}...\")\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=MODEL_ID,\n",
    "    device=device,\n",
    "    torch_dtype=dtype,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"\\n--- Estimating Generation Time ---\")\n",
    "test_samples = attack_df.head(3).copy()\n",
    "start_test = time.time()\n",
    "\n",
    "for idx, row in test_samples.iterrows():\n",
    "    prompt = generate_prompt_from_row(row)\n",
    "    # Generate with constraints to speed up\n",
    "    _ = pipe(prompt, max_new_tokens=200, do_sample=False, truncation=True)\n",
    "\n",
    "end_test = time.time()\n",
    "avg_time_per_sample = (end_test - start_test) / 3\n",
    "total_samples = len(attack_df)\n",
    "estimated_total_seconds = total_samples * avg_time_per_sample\n",
    "estimated_total_hours = estimated_total_seconds / 3600\n",
    "\n",
    "\n",
    "\n",
    "#Generation Loop\n",
    "print(f\"\\nStarting generation for {len(attack_df)} samples...\")\n",
    "explanations = []\n",
    "\n",
    "for idx, row in tqdm(attack_df.iterrows(), total=len(attack_df)):\n",
    "    prompt = generate_prompt_from_row(row)\n",
    "    \n",
    "    # Generate\n",
    "    outputs = pipe(\n",
    "        prompt, \n",
    "        max_new_tokens=128, \n",
    "        do_sample=True, \n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        truncation=True,\n",
    "        return_full_text=False \n",
    "    )\n",
    "    \n",
    "    explanation = outputs[0]['generated_text'].strip()\n",
    "    explanations.append(explanation)\n",
    "\n",
    "#save results\n",
    "attack_df['generated_explanation'] = explanations\n",
    "attack_df.to_csv(OUTPUT_DATA_PATH, index=False)\n",
    "print(f\"\\nDone! Explanations saved to {OUTPUT_DATA_PATH}\")\n",
    "\n",
    "# Print a few examples\n",
    "print(\"\\n--- Example Outputs ---\")\n",
    "for i in range(2):\n",
    "    print(f\"\\n[Label: {attack_df.iloc[i]['Fine Label']}]\")\n",
    "    print(f\"Explanation: {attack_df.iloc[i]['generated_explanation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bd1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
